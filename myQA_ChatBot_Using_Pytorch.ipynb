{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0498a8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Germany?</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
       "      <td>Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>Jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the boiling point of water in Celsius?</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question      answer\n",
       "0                   What is the capital of France?       Paris\n",
       "1                  What is the capital of Germany?      Berlin\n",
       "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
       "3  What is the largest planet in our solar system?     Jupiter\n",
       "4   What is the boiling point of water in Celsius?         100"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('QA_Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ed3eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('?',\"\")\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'is', 'the', 'capotal', 'of', 'france']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"What is the capotal of france?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee64aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab\n",
    "vocap = {'<UNK>':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocap(row):\n",
    "    tokenize_question = tokenize(row['question'])\n",
    "    tokenize_answer = tokenize(row['answer'])\n",
    "\n",
    "    merged_tokens = tokenize_question + tokenize_answer\n",
    "\n",
    "    for token in merged_tokens:\n",
    "        if token not in vocap:\n",
    "            vocap[token] = len(vocap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "621ae828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "      ... \n",
       "85    None\n",
       "86    None\n",
       "87    None\n",
       "88    None\n",
       "89    None\n",
       "Length: 90, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(build_vocap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0aeb9a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert words to numerical indices\n",
    "def text_to_indices(text, vocap):\n",
    "\n",
    "    indexed_text = []\n",
    "\n",
    "    for token in tokenize(text):\n",
    "        if token in vocap:\n",
    "            indexed_text.append(vocap[token])\n",
    "        else:\n",
    "            indexed_text.append(vocap['<UNK>'])\n",
    "\n",
    "    return indexed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "896e0c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_indices('what is AI',vocap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0de7976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, vocap):\n",
    "        self.df = df\n",
    "        self.vocap = vocap\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        numerical_question = text_to_indices(self.df.iloc[index]['question'],self.vocap)\n",
    "        numerical_answer = text_to_indices(self.df.iloc[index]['answer'],self.vocap)\n",
    "\n",
    "        return torch.tensor(numerical_question),torch.tensor(numerical_answer)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9c456fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QADataset(df, vocap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee56db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d89bc094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([185])\n",
      "tensor([[ 10,  75, 208]]) tensor([209])\n",
      "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([154])\n",
      "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([179])\n",
      "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([100])\n",
      "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([134])\n",
      "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([131])\n",
      "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([36])\n",
      "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([114])\n",
      "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([124])\n",
      "tensor([[ 10,  11, 189, 158, 190]]) tensor([191])\n",
      "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([316])\n",
      "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([128])\n",
      "tensor([[ 10,  29, 130, 131]]) tensor([132])\n",
      "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([155])\n",
      "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([121])\n",
      "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([307])\n",
      "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([321])\n",
      "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([173])\n",
      "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([246])\n",
      "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([298])\n",
      "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([145])\n",
      "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([254])\n",
      "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([215])\n",
      "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([6])\n",
      "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([249])\n",
      "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([285])\n",
      "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([61])\n",
      "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([205])\n",
      "tensor([[1, 2, 3, 4, 5, 8]]) tensor([9])\n",
      "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([162])\n",
      "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([170])\n",
      "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([54])\n",
      "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([225])\n",
      "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([287])\n",
      "tensor([[ 10,  96,   3, 104, 239]]) tensor([240])\n",
      "tensor([[10,  2,  3, 66,  5, 67]]) tensor([68])\n",
      "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([85])\n",
      "tensor([[10, 96,  3, 97]]) tensor([98])\n",
      "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([260])\n",
      "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([207])\n",
      "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([199])\n",
      "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([259])\n",
      "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([113])\n",
      "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([36])\n",
      "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([273])\n",
      "tensor([[ 42, 101,   2,   3,  17]]) tensor([102])\n",
      "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([106])\n",
      "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([91])\n",
      "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([136])\n",
      "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([317])\n",
      "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([72])\n",
      "tensor([[10, 11, 12, 13, 14, 15]]) tensor([16])\n",
      "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([85])\n",
      "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([276])\n",
      "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([156])\n",
      "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([220])\n",
      "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([280])\n",
      "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([244])\n",
      "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([194])\n",
      "tensor([[ 10,  11, 157, 158, 159]]) tensor([160])\n",
      "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([149])\n",
      "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([116])\n",
      "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([23])\n",
      "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([41])\n",
      "tensor([[1, 2, 3, 4, 5, 6]]) tensor([7])\n",
      "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([74])\n",
      "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([28])\n",
      "tensor([[10, 29,  3, 30, 31]]) tensor([32])\n",
      "tensor([[ 10,  75, 111]]) tensor([112])\n",
      "tensor([[10, 75, 76]]) tensor([77])\n",
      "tensor([[10, 55,  3, 56,  5, 57]]) tensor([58])\n",
      "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([95])\n",
      "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([184])\n",
      "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([49])\n",
      "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([36])\n",
      "tensor([[ 10, 308,   3, 309, 310]]) tensor([311])\n",
      "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([238])\n",
      "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([52])\n",
      "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([99])\n",
      "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([188])\n",
      "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([205])\n",
      "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([268])\n",
      "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([65])\n",
      "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([110])\n",
      "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([295])\n",
      "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([233])\n",
      "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([53])\n",
      "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([166])\n",
      "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([121])\n"
     ]
    }
   ],
   "source": [
    "for question, answer in dataloader:\n",
    "    print(question,answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce12eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd2c27f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, vocap_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocap_size, embedding_dim=50)\n",
    "        self.rnn = nn.RNN(50, 64, batch_first=True)\n",
    "        self.fc = nn.Linear(64, vocap_size)\n",
    "\n",
    "    def forward(self, question):\n",
    "        embedded_question = self.embedding(question)\n",
    "        hidden, final = self.rnn(embedded_question)\n",
    "        output = self.fc(final.squeeze(0))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bd4336e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of a: torch.Size([1, 6])\n",
      "shape of b: torch.Size([1, 6, 50])\n",
      "shape of c: torch.Size([1, 6, 64])\n",
      "shape of d torch.Size([1, 1, 64])\n",
      "shape of e: torch.Size([1, 324])\n"
     ]
    }
   ],
   "source": [
    "x = nn.Embedding(324, embedding_dim=50)\n",
    "y = nn.RNN(50, 64, batch_first=True)\n",
    "z = nn.Linear(64, 324)\n",
    "\n",
    "a = dataset[0][0].reshape(1, 6)\n",
    "print(\"shape of a:\",a.shape)\n",
    "b = x(a)\n",
    "print(\"shape of b:\",b.shape)\n",
    "c, d = y(b)\n",
    "print(\"shape of c:\", c.shape)\n",
    "print(\"shape of d\",d.shape)\n",
    "\n",
    "e = z(d.squeeze(0))\n",
    "print(\"shape of e:\", e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "343a3ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e175f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRNN(len(vocap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fce49e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e262c221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 523.261208\n",
      "Epoch: 2, Loss: 457.251402\n",
      "Epoch: 3, Loss: 379.807840\n",
      "Epoch: 4, Loss: 318.895488\n",
      "Epoch: 5, Loss: 267.586469\n",
      "Epoch: 6, Loss: 219.846695\n",
      "Epoch: 7, Loss: 176.508392\n",
      "Epoch: 8, Loss: 137.845261\n",
      "Epoch: 9, Loss: 106.527480\n",
      "Epoch: 10, Loss: 81.087821\n",
      "Epoch: 11, Loss: 62.196175\n",
      "Epoch: 12, Loss: 48.292679\n",
      "Epoch: 13, Loss: 38.093448\n",
      "Epoch: 14, Loss: 30.575837\n",
      "Epoch: 15, Loss: 25.028790\n",
      "Epoch: 16, Loss: 20.724072\n",
      "Epoch: 17, Loss: 17.550755\n",
      "Epoch: 18, Loss: 14.811636\n",
      "Epoch: 19, Loss: 12.737597\n",
      "Epoch: 20, Loss: 11.056089\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for question, answer in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        output = model(question)\n",
    "\n",
    "        # loss -> output shape(1, 324) - (1)\n",
    "        loss = criterion(output, answer[0])\n",
    "\n",
    "        # gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {total_loss:4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ba610ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "\n",
    "def predict(model, question, threshold=0.5):\n",
    "\n",
    "    #convert question to numbers\n",
    "    numerical_question = text_to_indices(question, vocap)\n",
    "\n",
    "    # tensor\n",
    "    question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
    "\n",
    "    # send to model\n",
    "    output = model(question_tensor)\n",
    "\n",
    "    # convert logits to probs\n",
    "    probs =  torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "    # find index to max prob\n",
    "    value, index = torch.max(probs, dim=1)\n",
    "\n",
    "    if value < threshold:\n",
    "        print(\"I don't know\")\n",
    "\n",
    "    print(list(vocap.keys())[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22bf6710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupiter\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"What is the largest planet in our solar system?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6cba132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paris'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocap.keys())[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c8f2533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 13:35:32.707 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.707 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.707 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.717 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.720 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.720 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.720 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.720 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.720 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.720 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.720 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.720 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.733 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-16 13:35:32.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
